{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cohort download",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ImagingDataCommons/IDC-Examples/blob/master/notebooks/Cohort_download.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrA0sBb8CIdv"
      },
      "source": [
        "# About\n",
        "\n",
        "This notebook is one of the examples that accompany NCI Imaging Data Commons. IDC example notebooks are located in this repository: https://github.com/ImagingDataCommons/IDC-Examples/tree/master/notebooks.\n",
        "\n",
        "# Working with IDC cohorts\n",
        "\n",
        "In this example we show how a cohort manifest defined using the [IDC Portal](https://portal.imaging.datacommons.cancer.gov/) can be used to download the data to a cloud VM instance.\n",
        "\n",
        "This example was prepared using a pre-release version of IDC Portal, and it has not yet been tested using the publicly released version.\n",
        "\n",
        "To proceed with the cells below you will need to \n",
        "* upload your manifest to the connected runtime file system\n",
        "* initialize `manifestLocalPath` in the cell below with the actual path to the uploaded manifest\n",
        "* initialize `myProjectID` in the cell below with a project ID that you can bill"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO5VZ_IBezx2"
      },
      "source": [
        "manifestLocalPath = \"##MANIFEST_LOCAL_PATH##\"\n",
        "myProjectID=\"##MY_PROJECT_ID##\""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPrIzB9gf668"
      },
      "source": [
        "!head $manifestLocalPath"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-D7_QONDbQ2"
      },
      "source": [
        "You can import IDC cohort manifest in CSV format as any other CSV file, but make sure you check the header to confirm how many lines need to be ignored. The header length may change leading to the public release of the portal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8_LJNP1e0Il"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def cohort_as_df(manifest_filename):\n",
        "  df = pd.read_csv(manifest_filename, header=5)\n",
        "  return df\n",
        "\n",
        "cohort_df = cohort_as_df(manifestLocalPath)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDSBOmiUDpxV"
      },
      "source": [
        "The manifest will contain a Google Storage URI (`gs://`) for each of the files corresponding to the individual DICOM instances. Here we save the column containing those URIs to enable download."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bife6XMuhWTD"
      },
      "source": [
        "print(cohort_df[\"gcs_path\"])\n",
        "cohort_df[\"gcs_path\"].to_csv(\"gcs_paths.txt\", header=False, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kXtIUh4hzO0"
      },
      "source": [
        "!head /content/gcs_paths.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUBm5K2TERvT"
      },
      "source": [
        "To download the files to the VM filesystem we can use the standard `gsutil` command, which is preinstalled on Colab instances."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEDaQPTPiM8p"
      },
      "source": [
        "# https://cloud.google.com/storage/docs/gsutil/commands/cp\n",
        "!cat gcs_paths.txt | gsutil -m cp -I ./downloaded_cohort"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqP67MonHBam"
      },
      "source": [
        "The command above will fail, since IDC-hosted data is stored in US multi-region [requester-pays Storage buckets](https://cloud.google.com/storage/docs/requester-pays). This means that you need to provide a project ID with billing configured to download the data. If you are using Google Colab from the US, the corresponding VM instance will likely be in the US, and data egress charges will be $0.01/GB (see  [GCP network egress charges](https://cloud.google.com/storage/pricing#network-buckets) for full details).\n",
        "\n",
        "Note that if you want to donwload the data to your own computer, the costs will be much higher.\n",
        "\n",
        "Before you can refer to a project that you own, you need to authenticate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVxG6QvteybL"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCjgz_DTnlgX"
      },
      "source": [
        "# https://cloud.google.com/storage/docs/gsutil/commands/cp\n",
        "!mkdir downloaded_cohort\n",
        "!cat gcs_paths.txt | gsutil -u $myProjectID -m cp -I ./downloaded_cohort"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cWqQ1cjIEKt"
      },
      "source": [
        "Now the data is located in the file storage local to the VM, but all of the files are in the same directory, which is not the most convenient layout.\n",
        "\n",
        "You can use the DICOM metadata to organize those instances, or use one of the existing tools to do this. One such tool is used below to organize the flat list of DICOM files into the PatientID-StudyInstanceUID-SeriesInstanceUID-SOPInstanceUID hierarchy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFUQAR0ti9hL",
        "outputId": "1d26b71e-ba86-4d34-cd0e-0a21e367c919",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "!git clone https://github.com/pieper/dicomsort.git\n",
        "!pip install pydicom\n",
        "!python dicomsort/dicomsort.py --help"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'dicomsort'...\n",
            "remote: Enumerating objects: 126, done.\u001b[K\n",
            "remote: Total 126 (delta 0), reused 0 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (126/126), 37.03 KiB | 1.61 MiB/s, done.\n",
            "Resolving deltas: 100% (63/63), done.\n",
            "Collecting pydicom\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/56/342e1f8ce5afe63bf65c23d0b2c1cd5a05600caad1c211c39725d3a4cc56/pydicom-2.0.0-py3-none-any.whl (35.4MB)\n",
            "\u001b[K     |████████████████████████████████| 35.5MB 1.3MB/s \n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.0.0\n",
            "\n",
            "% dicomsort.py --help\n",
            "dicomsort [options...] sourceDir targetDir/<patterns>\n",
            "\n",
            " where [options...] can be:\n",
            "    [-z,--compressTargets] - create a .zip file in the target directory\n",
            "    [-d,--deleteSource] - remove source files/directories after sorting\n",
            "    [-f,--forceDelete] - remove source without confirmation\n",
            "    [-k,--keepGoing] - report but ignore dupicate target files\n",
            "    [-v,--verbose] - print diagnostics while processing\n",
            "    [-s,--symlink] - create a symlink to dicom files in sourceDir instead of copying them\n",
            "    [-t,--test] - run the built in self test (requires internet)\n",
            "    [-u,--unsafe] - do not replace unsafe characters with '_' in the path\n",
            "    [--help] - print this message\n",
            "\n",
            " where sourceDir is directory to be scanned or \"\" (null string) to read file list from stdin\n",
            "\n",
            " where targetDir/<patterns...> is a string defining the output file and directory\n",
            " names based on the dicom tags in the file.\n",
            "\n",
            "If patterns are not specified, the following default is used:\n",
            "\n",
            "  %PatientName-%Modality%StudyID-%StudyDescription-%StudyDate/%SeriesNumber_%SeriesDescription-%InstanceNumber.dcm\n",
            "\n",
            "Example 1:\n",
            "\n",
            "  dicomsort data sorted/%PatientName/%StudyDate/%SeriesDescription-%InstanceNumber.dcm\n",
            "\n",
            "  could create a folder structure like:\n",
            "\n",
            "  sorted/JohnDoe/2013-40-18/FLAIR-2.dcm\n",
            "\n",
            "Example 2:\n",
            "\n",
            "  find DicomSourceDir/ | grep \"IMA$\" | dicomsort -s \"\" DicomTargetDir\n",
            "\n",
            "  would scan DicomSourceDir for file pathnames ending in IMA and create an\n",
            "  output directory DicomTargetDir. The folder structure will be created using\n",
            "  the default pattern with symbolic links to the source dicom data files.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_lE0c1FIvha"
      },
      "source": [
        "The command below will sort instances into folders based on the DICOM metadata stored in the corresponding files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sADXT6tukTu2",
        "outputId": "d0010fc8-4573-485b-ed9f-1e8d74e630e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!python dicomsort/dicomsort.py -u downloaded_cohort cohort_sorted/%PatientID/%StudyInstanceUID/%SeriesInstanceUID/%SOPInstanceUID.dcm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% 29/29 [00:02<00:00, 11.31it/s]\n",
            "Files sorted\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}