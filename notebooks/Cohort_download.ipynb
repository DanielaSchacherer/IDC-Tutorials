{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cohort download",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ImagingDataCommons/IDC-Examples/blob/master/notebooks/Cohort_download.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrA0sBb8CIdv"
      },
      "source": [
        "# Working with IDC cohorts\n",
        "\n",
        "This notebook is one of the examples that accompany NCI Imaging Data Commons. IDC example notebooks are located in this repository: https://github.com/ImagingDataCommons/IDC-Examples/tree/master/notebooks.\n",
        "\n",
        "In this example we show how a cohort manifest defined using the [IDC Portal](https://portal.imaging.datacommons.cancer.gov/) can be used to download the data to a cloud VM instance.\n",
        "\n",
        "To proceed with the cells below you will need to \n",
        "* upload your manifest to the connected runtime file system and set the `manifestLocalFile` below to point to that file OR export the cohort into a BigQuery table and set `cohortBQTable` to the table name\n",
        "* initialize `manifestLocalPath` in the cell below with the actual path to the uploaded manifest\n",
        "* initialize `myProjectID` in the cell below with your project ID (note: you do not need to configure billing for that project!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO5VZ_IBezx2"
      },
      "source": [
        "manifestLocalPath = \"##MANIFEST_LOCAL_PATH##\"\n",
        "cohortBQTable = \"##COHORT_BQ_TABLE##\"\n",
        "myProjectID=\"##MY_PROJECT_ID##\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tuVb1sCCjUV"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "You will need to authenticate with Google to be able to follow this example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVxG6QvteybL"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6is-ni21Ac1_"
      },
      "source": [
        "## Approach 1 (recommended): Get GCS URLs from a BigQuery table manifest\n",
        "\n",
        "Starting from Dec 2020 release, IDC portal allows to export cohort manifest either as a BigQuery table, or as one or more files.\n",
        "\n",
        "BigQuery export of the cohort manifest is the recommended approach. When exporting the manifest as a file, cohorts larger than 65,000 items will be exported as multiple files, and only up to 10 files for a multi-part cohort manifest can be exported. BigQuery manifest export does not have any limitations, and can be used in the same manner no matter how large or small is the cohort you want to export.\n",
        "\n",
        "First, let's get the GCS URLs for the items included in the cohort from the cohort manifest table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rsNuDaMB6wO"
      },
      "source": [
        "%%bigquery --project=$myProjectID cohort_df\n",
        "\n",
        "SELECT * \n",
        "FROM `##COHORT_BQ_TABLE##`"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hby9ej8AT4r"
      },
      "source": [
        "## Approach 2 (not recommended): Get GCS URLs from a manifest file\n",
        "\n",
        "We do not recommend this approach, since there is a limit of 650,000 rows on the manifest size that can be exported as a file, and also for any manifest containing more than 65,000 rows export into a file will be split into 65,000 rows chunks. See more details in https://learn.canceridc.dev/portal/data-exploration-and-cohorts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPrIzB9gf668"
      },
      "source": [
        "!head $manifestLocalPath"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-D7_QONDbQ2"
      },
      "source": [
        "You can import IDC cohort manifest in CSV format as any other CSV file, but make sure you check the header to confirm how many lines need to be ignored. The header length may change leading to the public release of the portal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8_LJNP1e0Il"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def cohort_as_df(manifest_filename):\n",
        "  df = pd.read_csv(manifest_filename, header=5)\n",
        "  return df\n",
        "\n",
        "cohort_df = cohort_as_df(manifestLocalPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDSBOmiUDpxV"
      },
      "source": [
        "## Save the GCS URLs and download the corresponding instances\n",
        "\n",
        "Due to a known issue in the current release of IDC, we need to do remove the generation suffix from `gcs_url`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bife6XMuhWTD"
      },
      "source": [
        "cohort_df = cohort_df.join(cohort_df[\"gcs_url\"].str.split('#', 1, expand=True).rename(columns={0:'gcs_url_no_revision', 1:'gcs_revision'}))\n",
        "cohort_df[\"gcs_url_no_revision\"].to_csv(\"gcs_paths.txt\", header=False, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kXtIUh4hzO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85dda7f4-7276-47d1-95a5-fa2b217179c5"
      },
      "source": [
        "!head /content/gcs_paths.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gs://idc-tcia-nsclc-radiomics/dicom/1.3.6.1.4.1.32722.99.99.203715003805996641695765332389135385095/1.2.276.0.7230010.3.1.3.2323910823.11504.1597260515.421/1.2.276.0.7230010.3.1.4.2323910823.11504.1597260515.422.dcm\n",
            "gs://idc-tcia-nsclc-radiomics/dicom/1.3.6.1.4.1.32722.99.99.247726286795860121686796574974227334270/1.2.276.0.7230010.3.1.3.2323910823.23864.1597260522.316/1.2.276.0.7230010.3.1.4.2323910823.23864.1597260522.317.dcm\n",
            "gs://idc-tcia-nsclc-radiomics/dicom/1.3.6.1.4.1.32722.99.99.71961866280433925571019872464419293819/1.2.276.0.7230010.3.1.3.2323910823.11644.1597260534.485/1.2.276.0.7230010.3.1.4.2323910823.11644.1597260534.486.dcm\n",
            "gs://idc-tcia-nsclc-radiomics/dicom/1.3.6.1.4.1.32722.99.99.270361505197008655909592732352678399263/1.2.276.0.7230010.3.1.3.2323910823.21456.1597260540.379/1.2.276.0.7230010.3.1.4.2323910823.21456.1597260540.380.dcm\n",
            "gs://idc-tcia-nsclc-radiomics/dicom/1.3.6.1.4.1.32722.99.99.282967364651788470277412461462049836277/1.2.276.0.7230010.3.1.3.2323910823.22444.1597260547.585/1.2.276.0.7230010.3.1.4.2323910823.22444.1597260547.586.dcm\n",
            "gs://idc-tcia-nsclc-radiomics/dicom/1.3.6.1.4.1.32722.99.99.62087908186665265759322018723889952421/1.2.276.0.7230010.3.1.3.2323910823.1956.1597260554.647/1.2.276.0.7230010.3.1.4.2323910823.1956.1597260554.648.dcm\n",
            "gs://idc-tcia-nsclc-radiomics/dicom/1.3.6.1.4.1.32722.99.99.325293684872203513909374292566067254264/1.2.276.0.7230010.3.1.3.2323910823.20804.1597260568.342/1.2.276.0.7230010.3.1.4.2323910823.20804.1597260568.343.dcm\n",
            "gs://idc-tcia-nsclc-radiomics/dicom/1.3.6.1.4.1.32722.99.99.296671185037042336554084207394991764935/1.2.276.0.7230010.3.1.3.2323910823.19496.1597260575.3/1.2.276.0.7230010.3.1.4.2323910823.19496.1597260575.4.dcm\n",
            "gs://idc-tcia-nsclc-radiomics/dicom/1.3.6.1.4.1.32722.99.99.148669307175250706097043711484224542151/1.2.276.0.7230010.3.1.3.2323910823.17176.1597260583.102/1.2.276.0.7230010.3.1.4.2323910823.17176.1597260583.103.dcm\n",
            "gs://idc-tcia-nsclc-radiomics/dicom/1.3.6.1.4.1.32722.99.99.62174692101933124338373944934297606346/1.2.276.0.7230010.3.1.3.2323910823.21208.1597260597.918/1.2.276.0.7230010.3.1.4.2323910823.21208.1597260597.919.dcm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqP67MonHBam"
      },
      "source": [
        "To download the files to the VM filesystem we can use the standard `gsutil` command, which is preinstalled on Colab instances.\n",
        "\n",
        "IDC-hosted data is stored is available from free Google Storage buckets maintained under [Google Public Dataset Program](https://console.cloud.google.com/marketplace/product/gcp-public-data-idc/nci-idc-data), which sponsors free egress of the data either within or out of the Google Cloud."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCjgz_DTnlgX"
      },
      "source": [
        "# https://cloud.google.com/storage/docs/gsutil/commands/cp\n",
        "!mkdir downloaded_cohort\n",
        "!cat gcs_paths.txt | gsutil -m cp -I ./downloaded_cohort"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cWqQ1cjIEKt"
      },
      "source": [
        "Now the data is located in the file storage local to the VM, but all of the files are in the same directory, which is not the most convenient layout.\n",
        "\n",
        "You can use the DICOM metadata to organize those instances, or use one of the existing tools to do this. One such tool is used below to organize the flat list of DICOM files into the PatientID-StudyInstanceUID-SeriesInstanceUID-SOPInstanceUID hierarchy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFUQAR0ti9hL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "1d26b71e-ba86-4d34-cd0e-0a21e367c919"
      },
      "source": [
        "!git clone https://github.com/pieper/dicomsort.git\n",
        "!pip install pydicom\n",
        "!python dicomsort/dicomsort.py --help"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'dicomsort'...\n",
            "remote: Enumerating objects: 126, done.\u001b[K\n",
            "remote: Total 126 (delta 0), reused 0 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (126/126), 37.03 KiB | 1.61 MiB/s, done.\n",
            "Resolving deltas: 100% (63/63), done.\n",
            "Collecting pydicom\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/56/342e1f8ce5afe63bf65c23d0b2c1cd5a05600caad1c211c39725d3a4cc56/pydicom-2.0.0-py3-none-any.whl (35.4MB)\n",
            "\u001b[K     |████████████████████████████████| 35.5MB 1.3MB/s \n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.0.0\n",
            "\n",
            "% dicomsort.py --help\n",
            "dicomsort [options...] sourceDir targetDir/<patterns>\n",
            "\n",
            " where [options...] can be:\n",
            "    [-z,--compressTargets] - create a .zip file in the target directory\n",
            "    [-d,--deleteSource] - remove source files/directories after sorting\n",
            "    [-f,--forceDelete] - remove source without confirmation\n",
            "    [-k,--keepGoing] - report but ignore dupicate target files\n",
            "    [-v,--verbose] - print diagnostics while processing\n",
            "    [-s,--symlink] - create a symlink to dicom files in sourceDir instead of copying them\n",
            "    [-t,--test] - run the built in self test (requires internet)\n",
            "    [-u,--unsafe] - do not replace unsafe characters with '_' in the path\n",
            "    [--help] - print this message\n",
            "\n",
            " where sourceDir is directory to be scanned or \"\" (null string) to read file list from stdin\n",
            "\n",
            " where targetDir/<patterns...> is a string defining the output file and directory\n",
            " names based on the dicom tags in the file.\n",
            "\n",
            "If patterns are not specified, the following default is used:\n",
            "\n",
            "  %PatientName-%Modality%StudyID-%StudyDescription-%StudyDate/%SeriesNumber_%SeriesDescription-%InstanceNumber.dcm\n",
            "\n",
            "Example 1:\n",
            "\n",
            "  dicomsort data sorted/%PatientName/%StudyDate/%SeriesDescription-%InstanceNumber.dcm\n",
            "\n",
            "  could create a folder structure like:\n",
            "\n",
            "  sorted/JohnDoe/2013-40-18/FLAIR-2.dcm\n",
            "\n",
            "Example 2:\n",
            "\n",
            "  find DicomSourceDir/ | grep \"IMA$\" | dicomsort -s \"\" DicomTargetDir\n",
            "\n",
            "  would scan DicomSourceDir for file pathnames ending in IMA and create an\n",
            "  output directory DicomTargetDir. The folder structure will be created using\n",
            "  the default pattern with symbolic links to the source dicom data files.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_lE0c1FIvha"
      },
      "source": [
        "The command below will sort instances into folders based on the DICOM metadata stored in the corresponding files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sADXT6tukTu2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d0010fc8-4573-485b-ed9f-1e8d74e630e2"
      },
      "source": [
        "!python dicomsort/dicomsort.py -u downloaded_cohort cohort_sorted/%PatientID/%StudyInstanceUID/%SeriesInstanceUID/%SOPInstanceUID.dcm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% 29/29 [00:02<00:00, 11.31it/s]\n",
            "Files sorted\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}